

# å°†judge_responseä¸­çš„ä¿¡æ¯æå–å‡ºæ¥ï¼Œæ·»åŠ åˆ°jsonæ–‡ä»¶ä¸­

import json
import re

# def extract_info(text):
#     # æ­£åˆ™åŒ¹é…å„å­—æ®µï¼Œå…è®¸å‰åæœ‰ç©ºæ ¼ï¼Œå¤§å°å†™ä¸æ•æ„Ÿ
#     # role_match = re.search(r"(?i)Role:\s*(.*?)\.", text)
#     role_match = re.search(r"(?i)Role:\s*(.*?)(?:[\n\.])", text)
#     stance_match = re.search(r"(?i)Stance:\s*(.*?)\n", text)
#     confidence_match = re.search(r"(?i)Confidence:\s*(.*?)\.", text)
#     noisy_items_line = re.search(r"(?i)Noisy Items:\s*([0-9,\s]+)", text)
#     explanation_match = re.search(r"(?i)Explanation:\s*(.*)", text, re.DOTALL)

#     # å¦‚æœ noisy_items è¡Œå­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨
#     if noisy_items_line:
#         noisy_items = [int(item.strip()) for item in noisy_items_line.group(1).split(",") if item.strip().isdigit()]
#     else:
#         # å¦‚æœæ²¡æœ‰æ˜ç¡® noisy_items å­—æ®µï¼Œä»æ­£æ–‡ä¸­æ‰¾ (IDs xxx)
#         noisy_items_inline = re.findall(r"\(IDs? ([\d,\s]+)\)", text)
#         noisy_items = []
#         for match in noisy_items_inline:
#             noisy_items.extend([int(item.strip()) for item in match.split(",") if item.strip().isdigit()])

#     return {
#         "Role": role_match.group(1).strip() if role_match else None,
#         "Stance": stance_match.group(1).strip() if stance_match else None,
#         "Confidence": confidence_match.group(1).strip() if confidence_match else None,
#         "Noisy Items": noisy_items if noisy_items else None,
#         "Explanation": explanation_match.group(1).strip() if explanation_match else None
#     }

# import re

# def extract_info(text):
#     # ç»Ÿä¸€é¢„å¤„ç†ï¼šæ›¿æ¢æ–¹æ‹¬å·ä¸ºé€—å·ï¼ˆä¾‹å¦‚ [352] -> 352ï¼‰
#     normalized_text = re.sub(r'$$([\d\s,]+)$$', r'\1', text)  # å¤„ç†[352]æ ¼å¼
    
#     # æ­£åˆ™åŒ¹é…å„å­—æ®µï¼ˆå…¼å®¹å¤§å°å†™ã€ç©ºæ ¼ã€æ¢è¡Œç¬¦ï¼‰
#     role_match = re.search(r"(?i)Role:\s*(.*?)(?:[\n\.])", normalized_text)
#     stance_match = re.search(r"(?i)Stance:\s*(.*?)\n", normalized_text)
#     confidence_match = re.search(r"(?i)Confidence:\s*(.*?)\.", normalized_text)
#     explanation_match = re.search(r"(?i)Explanation:\s*(.*)", normalized_text, re.DOTALL)
    
#     # æ”¹è¿›çš„Noisy Itemsæå–ï¼ˆå…¼å®¹ä¸‰ç§æ ¼å¼ï¼‰ï¼š
#     noisy_items = []
#     # æƒ…å†µ1ï¼šæ˜¾å¼å£°æ˜çš„"Noisy Items:"è¡Œï¼ˆå…¼å®¹é€—å·/ç©ºæ ¼/æ–¹æ‹¬å·ï¼‰
#     noisy_line_match = re.search(r"(?i)Noisy Items:\s*([$$$$\d\s,]+)", normalized_text)
#     if noisy_line_match:
#         raw_items = re.sub(r'[$$$$\s]', '', noisy_line_match.group(1))  # ç§»é™¤æ‰€æœ‰æ–¹æ‹¬å·å’Œç©ºæ ¼
#         noisy_items.extend([int(x) for x in raw_items.split(",") if x.strip().isdigit()])
    
#     # æƒ…å†µ2ï¼šä»æ­£æ–‡ä¸­æŸ¥æ‰¾ (IDs xxx) çš„éšå¼å£°æ˜
#     if not noisy_items:
#         noisy_items_inline = re.findall(r"$IDs? ([\d\s,]+)$", normalized_text)
#         for match in noisy_items_inline:
#             noisy_items.extend([int(x) for x in match.replace(" ", "").split(",") if x.strip().isdigit()])
    
#     # # æƒ…å†µ3ï¼šçº¯æ•°å­—è¡Œï¼ˆå¦‚ä»…å‡ºç°"[352]"æ— å‰ç¼€ï¼‰
#     # if not noisy_items:
#     #     standalone_items = re.findall(r'(?<!\d)\b(\d{3,})\b(?!\d)', normalized_text)  # åŒ¹é…3ä½ä»¥ä¸Šç‹¬ç«‹æ•°å­—
#     #     noisy_items.extend([int(x) for x in standalone_items if x.isdigit()])

#     return {
#         "Role": role_match.group(1).strip() if role_match else None,
#         "Stance": stance_match.group(1).strip() if stance_match else None,
#         "Confidence": confidence_match.group(1).strip() if confidence_match else None,
#         "Noisy Items": noisy_items if noisy_items else None,
#         "Explanation": explanation_match.group(1).strip() if explanation_match else None
#     }

# import re

# def extract_info(text):
#     # ç»Ÿä¸€é¢„å¤„ç†ï¼šæ›¿æ¢æ–¹æ‹¬å·ä¸ºé€—å·ï¼ˆä¾‹å¦‚ [352] -> 352ï¼‰
#     normalized_text = re.sub(r'\[([\d\s,]+)\]', r'\1', text)  # æ³¨æ„è¿™é‡ŒåŸä»£ç å†™é”™äº†ç”¨ `$$`

#     # æ”¾å®½åŒ¹é…è§„åˆ™ï¼Œå…¼å®¹ **åŠ ç²—** æ ¼å¼
#     role_match = re.search(r"(?i)Role:\s*\**(.*?)\**[\n\.]", normalized_text)
#     stance_match = re.search(r"(?i)Stance:\s*\**(.*?)\**[\n\.]", normalized_text)
#     confidence_match = re.search(r"(?i)Confidence:\s*\**(.*?)\**[\n\.]", normalized_text)
#     explanation_match = re.search(r"(?i)Explanation:\s*(.*)", normalized_text, re.DOTALL)

#     # æ”¹è¿› Noisy Items æå–
#     noisy_items = []

#     # æƒ…å†µ1ï¼šæ˜¾å¼ "Noisy Items: **xxx**"
#     noisy_line_match = re.search(r"(?i)Noisy Items:\s*\**([0-9,\s]+)\**", normalized_text)
#     if noisy_line_match:
#         raw_items = noisy_line_match.group(1)
#         noisy_items.extend([int(x.strip()) for x in raw_items.split(",") if x.strip().isdigit()])

#     # æƒ…å†µ2ï¼šæ­£æ–‡å†… IDs xxx
#     if not noisy_items:
#         noisy_items_inline = re.findall(r"IDs?[\s:]*([\d\s,]+)", normalized_text)
#         for match in noisy_items_inline:
#             noisy_items.extend([int(x) for x in match.replace(" ", "").split(",") if x.strip().isdigit()])

#     return {
#         "Role": role_match.group(1).strip() if role_match else None,
#         "Stance": stance_match.group(1).strip() if stance_match else None,
#         "Confidence": confidence_match.group(1).strip() if confidence_match else None,
#         "Noisy Items": noisy_items if noisy_items else None,
#         "Explanation": explanation_match.group(1).strip() if explanation_match else None
#     }

import re

def extract_field(text, label):
    # ä¼˜å…ˆåŒ¹é…åŠ ç²—æ ¼å¼ï¼ˆ**å†…å®¹**ï¼‰
    match = re.search(rf"(?i){label}:\s*\*\*(.*?)\*\*", text)
    if match:
        return match.group(1).strip()
    # å›é€€ï¼šåŒ¹é…éåŠ ç²—æ ¼å¼ï¼ˆä»¥æ¢è¡Œæˆ–å¥å·ç»“å°¾ï¼‰
    match = re.search(rf"(?i){label}:\s*(.*?)(?:[\n\.])", text)
    return match.group(1).strip() if match else None

def extract_info(text):
    # å¯é€‰é¢„å¤„ç†ï¼šå»é™¤ $ å½¢å¼çš„åŒ…è£¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    normalized_text = re.sub(r'[$]+([\d\s,]+)[$]+', r'\1', text)  # å¤„ç† $$352$$ã€$352$ ç­‰

    # æå–å­—æ®µï¼ˆå…¼å®¹åŠ ç²—æ ¼å¼ï¼‰
    role = extract_field(normalized_text, "Role")
    stance = extract_field(normalized_text, "Stance")
    confidence = extract_field(normalized_text, "Confidence")

    # æå– Explanationï¼ˆå¯èƒ½è¾ƒé•¿ï¼Œé€šå¸¸åœ¨æœ€åï¼‰
    explanation_match = re.search(r"(?i)Explanation:\s*\**(.*?)\**\s*$", normalized_text, re.DOTALL)
    explanation = explanation_match.group(1).strip() if explanation_match else None

    # æå– noisy items
    noisy_items = []

    # æ˜¾å¼ Noisy Items å­—æ®µï¼ˆæ”¯æŒ **1840** / [1840] / 1840 å½¢å¼ï¼‰
    noisy_line_match = re.search(r"(?i)Noisy Items:\s*\**([$\d\s,\[\]]+)\**", normalized_text)
    if noisy_line_match:
        raw = noisy_line_match.group(1)
        cleaned = re.sub(r'[\[\]\s]', '', raw)  # å»é™¤æ‹¬å·ã€ç©ºæ ¼
        noisy_items = [int(x) for x in cleaned.split(',') if x.strip().isdigit()]

    # éšå¼å½¢å¼ï¼šå¦‚ IDs 1840, 2321
    if not noisy_items:
        inline_matches = re.findall(r"IDs?\s+([\d\s,]+)", normalized_text)
        for match in inline_matches:
            noisy_items += [int(x) for x in match.replace(" ", "").split(",") if x.strip().isdigit()]

    return {
        "Role": role,
        "Stance": stance,
        "Confidence": confidence,
        "Noisy Items": noisy_items if noisy_items else None,
        "Explanation": explanation
    }


# # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„
# output_path = input_path = "/home/aiding/multi-agent-debate-rec/debate/data/S1_Games_qwen3_8b_debate_dict.json"
# #  "/home/aiding/LoRec/debate/data/10samples_32B_debate_dict.json"

# # è¯»å– json æ–‡ä»¶
# with open(input_path, "r", encoding="utf-8") as f:
#     data = json.load(f)

# # å¤„ç†æ¯ä¸ªç”¨æˆ·
# for user_id, user_info in data.items():
#     text = user_info.get("Final_Judge_Response", "")
#     result = extract_info(text)
#     user_info["final_result"] = result

# # å†™å› json æ–‡ä»¶
# with open(output_path, "w", encoding="utf-8") as f:
#     json.dump(data, f, indent=2, ensure_ascii=False)




# # ç»Ÿè®¡rolesï¼Œconfidenceï¼Œnoisy_itemsçš„æ•°é‡åˆ†å¸ƒ

# import json
# from collections import Counter

# # è¯»å–æ•°æ®
# with open("/home/aiding/multi-agent-debate-rec/debate/data/S3_qwen3_8b_debate_dict.json", "r") as f:
#     data = json.load(f)

# # æ”¶é›† Role å’Œ Confidence å­—æ®µ
# roles = []
# confidences = []
# noisy_lengths = []

# for user_id, user_data in data.items():
#     result = user_data.get("final_result", {})
#     if result:
#         role = result.get("Role")
#         confidence = result.get("Confidence")
#         noisy_items = result.get("Noisy Items", [])
#         if role:
#             roles.append(role)
#         if confidence:
#             confidences.append(confidence)
#         if isinstance(noisy_items, list):
#             noisy_lengths.append(len(noisy_items))

# # ç»Ÿè®¡é¢‘æ¬¡
# role_counter = Counter(roles)
# confidence_counter = Counter(confidences)

# # è®¡ç®—æ€»æ•°
# total_roles = sum(role_counter.values())
# total_confidences = sum(confidence_counter.values())

# length_counter = Counter(noisy_lengths)
# total = sum(length_counter.values())

# # è¾“å‡ºå æ¯”
# print("\nğŸ“Œ Role åˆ†å¸ƒ:")
# for role, count in role_counter.items():
#     print(f"{role}: {count} ({count / total_roles:.2%})")

# print("\nğŸ“Œ Confidence åˆ†å¸ƒ:")
# for conf, count in confidence_counter.items():
#     print(f"{conf}: {count} ({count / total_confidences:.2%})")

# print("\nğŸ“Œ Noisy Items é•¿åº¦åˆ†å¸ƒ:")
# for length, count in sorted(length_counter.items()):
#     print(f"{length} ä¸ª: {count} ç”¨æˆ· ({count / total:.2%})")



# # # å°† noisy_items æå–å‡ºæ¥ï¼Œä¿å­˜åˆ° json æ–‡ä»¶ä¸­
# import json
# from collections import Counter

# def save_noisy_items_to_json(input_path, output_path):
#     # è¯»å–æ•°æ®
#     with open(input_path, "r") as f:
#         data = json.load(f)

#     noisy_items_dict = {}
#     for user_id, user_data in data.items():
#         # if int(user_id) <= 400 or int(user_id) >= 601:
#         # if int(user_id) <= 1000 and int(user_id) >= 601:
#         # if int(user_id) >= 401:
#             result = user_data.get("final_result", {})
#             # import pdb;pdb.set_trace()
#             if result:
#                 role = result.get("Role")
#                 # if role == "Noisy User Analyst" or role == "Noisy_User_Analyst" or role == "Judge":
#                 if role == "Noisy User Analyst" and result.get("Noisy Items", []) is not None:
#                     noisy_items_dict[user_id] = result.get("Noisy Items", [])
#                     # noisy_items_dict[str(int(user_id) + 1000)] = result.get("Noisy Items", [])

#     # å†™å› json æ–‡ä»¶
#     with open(output_path, "w", encoding="utf-8") as f:
#         json.dump(noisy_items_dict, f, indent=2, ensure_ascii=False)

# input_path = "/home/aiding/multi-agent-debate-rec/check/checkpoints/20260502_arts1000dense_qwen25_32b_debate_dict.json"
# # input_path = "/home/aiding/multi-agent-debate-rec/debate/data/20260519_games1000dense_qwen3_8b_debate_dict.json"
# # input_path = "/home/aiding/multi-agent-debate-rec/debate/data/S1_Games_qwen3_8b_debate_dict.json"
# # input_path = "/home/aiding/multi-agent-debate-rec/debate/data/S2_Games_qwen3_8b_debate_dict.json"
# # output_path = "/home/aiding/multi-agent-debate-rec/data/Games1000S1/attack_noisy_items.json"
# output_path = "/home/aiding/multi-agent-debate-rec/data/Arts1000denoising/noisy_items.json"
# # output_path = "/home/aiding/multi-agent-debate-rec/data/Games1000denoising/noisy_items.json"
# save_noisy_items_to_json(input_path, output_path)



# # æ ¹æ®noisy_itemsæ›´æ–° user_dict
# import json

# # åŠ è½½æ•°æ®
# # with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/noisy_items.json", "r") as f:
# with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/noisy_items.json", "r") as f:
# # with open("/home/aiding/multi-agent-debate-rec/data/Games1000S1/noisy_items.json", "r") as f:
#     noisy_items_dict = json.load(f)

# with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/user_dict.json", "r") as f:
#     user_dict = json.load(f)

# noisy_count = 0
# # åˆ é™¤å¯¹åº”çš„ noisy_itemsï¼Œä¿ç•™é•¿åº¦>=3çš„
# for user_id, noisy_items in noisy_items_dict.items():
#     if not isinstance(noisy_items, list):
#         continue  # è·³è¿‡ä¸æ˜¯åˆ—è¡¨çš„æƒ…å†µ

#     # if user_id in user_dict and len(noisy_items) <= 3:
#     if user_id in user_dict:
#         user_items = user_dict[user_id]
#         filtered_items = [item for item in user_items if item not in noisy_items]
        
#         # if len(filtered_items) >= 3:
#         if len(filtered_items) >= 2:
#             user_dict[user_id] = filtered_items
#             noisy_count += len(user_items) - len(filtered_items)
#         # å¦åˆ™ä¸ä¿®æ”¹ï¼Œä¿ç•™åŸå§‹ user_items

# # ä¿å­˜ä¿®æ”¹åçš„ user_dict
# with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/user_dict.json", "w") as f:
#     json.dump(user_dict, f, indent=2)

# print(f"Done. Total noisy items removed: {noisy_count}")




# åˆ é™¤ user_dict ä¸­ role æ˜¯ Fraud Investigator çš„ç”¨æˆ·
import json

# è¯»å–32Bæ¨ç†ç»“æœ
# with open("/home/aiding/LoRec/debate/data/32B_new_debate_dict.json", "r") as f:
with open("/home/aiding/multi-agent-debate-rec/check/checkpoints/20260430_games1000dense_qwen3_32b_debate_dict.json", "r") as f:
# with open("/home/aiding/multi-agent-debate-rec/debate/data/S3_Games_qwen3_8b_debate_dict.json", "r") as f:
# with open("/home/aiding/multi-agent-debate-rec/debate/data/20260519_games1000dense_qwen3_8b_debate_dict.json", "r") as f:
# with open("/home/aiding/LoRec/debate/data/20260430_arts1000dense_qwen3_32b_debate_dict.json", "r") as f:
    debate_data = json.load(f)

# è¯»å–ç”¨æˆ·åºåˆ—æ•°æ®
# with open("/home/aiding/LoRec/data/arts1000denoising/user_dict.json", "r") as f:
with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/user_dict.json", "r") as f:
# with open("/home/aiding/LoRec/data/Arts1000dense/user_dict.json", "r") as f:
    user_dict = json.load(f)

# æ‰¾å‡ºéœ€è¦åˆ é™¤çš„ user_idï¼ˆrole æ˜¯ Fraud Investigatorï¼‰
to_delete = set()
for user_id, user_data in debate_data.items():
    result = user_data.get("final_result", {})
    if result.get("Role") == "Fraud Investigator":
        to_delete.add(user_id)

# åˆ é™¤è¿™äº›ç”¨æˆ·
filtered_user_dict = {
    user_id: items
    for user_id, items in user_dict.items()
    if user_id not in to_delete
}

# é‡æ–°ç¼–å· user_idï¼Œä»1å¼€å§‹
new_user_dict = {}
for idx, (old_user_id, items) in enumerate(filtered_user_dict.items(), start=1):
    new_user_dict[str(idx)] = items

# ä¿å­˜ç»“æœ
with open("/home/aiding/multi-agent-debate-rec/data/Games1000S3/user_dict.json", "w") as f:
# with open("/home/aiding/LoRec/data/arts1000denoising/user_dict.json", "w") as f:
    json.dump(new_user_dict, f, indent=2)

print(f"Done. Final user count: {len(new_user_dict)}")

            



# # ç»Ÿè®¡noisy_itemsä¸­target_itemçš„æ•°é‡
# # target_item = [
# #         38646,
# #         60510,
# #         54053,
# #         2524,
# #         36130
# #     ]
# target_item = [
#         1699,
#         2680,
#         2384,
#         102,
#         1576
#     ]

# # è¯»å–æ•°æ®
# with open("/home/aiding/LoRec/debate/data/32B_attack_debate_dict.json", "r") as f:
#     data = json.load(f)

# count = 0
# for user_id, user_data in data.items():
#     result = user_data.get("final_result", {})
#     if result:
#         role = result.get("Role")
#         # if role == "Noisy User Analyst" or role == "Noisy_User_Analyst" or role == "Judge":
#         if role == "Noisy User Analyst":
#             noisy_items_list = result.get("Noisy Items", [])
#             if noisy_items_list is not None:
#                 for target in target_item:
#                     if target in noisy_items_list:
#                         print(f"User {user_id} has target item {target} in noisy items.")
#                         count += 1
# print(f"Total users with target items in noisy items: {count}")